{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dask_ml.preprocessing import Categorizer\n",
    "from glum import GeneralizedLinearRegressor, TweedieDistribution\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, SplineTransformer, StandardScaler\n",
    "#import everything here in the masterfile\n",
    "#kernels sometimes need to be restarted when new lib installed\n",
    "import dalex as dx\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Getting project root\n",
    "project_root = Path.cwd().resolve().parent\n",
    "\n",
    "# Add the project root directory to sys.path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "\n",
    "from ps3.data import create_sample_split, load_transform\n",
    "from evaluation.evaluate_predictions import evaluate_predictions\n",
    "#from ps3.data import train_tweedie, model_pipeline, spline_model\n",
    "#only if code reworked modularly, currently not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = load_transform()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to ensure IDpol column is unique - we shall carry out split on this\n",
    "len(df[\"IDpol\"].unique()) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train benchmark tweedie model. This is entirely based on the glum tutorial.\n",
    "#weight = df[\"Exposure\"].values\n",
    "df[\"PurePremium\"] = df[\"ClaimAmountCut\"] / df[\"Exposure\"]\n",
    "\n",
    "outcome = \"PurePremium\"\n",
    "# TODO: Why do you think, we divide by exposure here to arrive at our outcome variable?\n",
    "'''\n",
    "To get a yearly figure so we can compare claims that have a different time under risk\n",
    "'''\n",
    "\n",
    "\n",
    "# TODO: use your create_sample_split function here\n",
    "df_split = create_sample_split(df,\"IDpol\",0.8)\n",
    "df_train = df_split[0].copy()\n",
    "df_test = df_split[1].copy()\n",
    "\n",
    "\n",
    "categoricals = [\"VehBrand\", \"VehGas\", \"Region\", \"Area\", \"DrivAge\", \"VehAge\", \"VehPower\"]\n",
    "\n",
    "predictors = categoricals + [\"BonusMalus\", \"Density\"]\n",
    "glm_categorizer = Categorizer(columns=categoricals)\n",
    "\n",
    "\n",
    "X_train_t = glm_categorizer.fit_transform(df_train[predictors])\n",
    "X_test_t = glm_categorizer.transform(df_test[predictors])\n",
    "y_train_t, y_test_t = df_train[outcome], df_test[outcome]\n",
    "w_train_t, w_test_t = df_train[\"Exposure\"], df_test[\"Exposure\"]\n",
    "\n",
    "TweedieDist = TweedieDistribution(1.5)\n",
    "t_glm1 = GeneralizedLinearRegressor(family=TweedieDist, l1_ratio=1, fit_intercept=True)\n",
    "t_glm1.fit(X_train_t, y_train_t, sample_weight=w_train_t)\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\"coefficient\": np.concatenate(([t_glm1.intercept_], t_glm1.coef_))},\n",
    "    index=[\"intercept\"] + t_glm1.feature_names_,\n",
    ").T\n",
    "\n",
    "df_test.loc[:,\"pp_t_glm1\"] = t_glm1.predict(X_test_t)\n",
    "df_train.loc[:,\"pp_t_glm1\"] = t_glm1.predict(X_train_t)\n",
    "\n",
    "print(\n",
    "    \"training loss t_glm1:  {}\".format(\n",
    "        TweedieDist.deviance(y_train_t, df_train[\"pp_t_glm1\"], sample_weight=w_train_t)\n",
    "        / np.sum(w_train_t)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"testing loss t_glm1:  {}\".format(\n",
    "        TweedieDist.deviance(y_train_t, df_train[\"pp_t_glm1\"], sample_weight=w_train_t)\n",
    "        / np.sum(w_train_t)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Total claim amount on train set, observed = {}, predicted = {}\".format(\n",
    "        df_train[\"ClaimAmountCut\"].values.sum(),\n",
    "        np.sum(df_test[\"Exposure\"].values * t_glm1.predict(X_test_t)),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Let's add splines for BonusMalus and Density and use a Pipeline.\n",
    "# Steps: \n",
    "# 1. Define a Pipeline which chains a StandardScaler and SplineTransformer. \n",
    "#    Choose knots=\"quantile\" for the SplineTransformer and make sure, we \n",
    "#    are only including one intercept in the final GLM. \n",
    "# 2. Put the transforms together into a ColumnTransformer. Here we use OneHotEncoder for the categoricals.\n",
    "# 3. Chain the transforms together with the GLM in a Pipeline.\n",
    "categoricals = [\"VehBrand\", \"VehGas\", \"Region\", \"Area\", \"DrivAge\", \"VehAge\", \"VehPower\"]\n",
    "# Let's put together a pipeline\n",
    "numeric_cols = [\"BonusMalus\", \"Density\"]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # TODO: Add numeric transforms here\n",
    "        (\"cat\", OneHotEncoder(sparse_output=False, drop=\"first\"), categoricals),\n",
    "        (\"spline\", SplineTransformer(knots=\"quantile\"), numeric_cols),\n",
    "        (\"scale\", StandardScaler(), numeric_cols)\n",
    "    ]\n",
    ")\n",
    "preprocessor.set_output(transform=\"pandas\")\n",
    "model_pipeline = Pipeline(\n",
    "    # TODO: Define pipeline steps here\n",
    "    [\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\n",
    "            \"estimate\",\n",
    "            GeneralizedLinearRegressor(\n",
    "                family=TweedieDist, l1_ratio=1, fit_intercept=True\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#incorporate this part later\n",
    "# let's have a look at the pipeline\n",
    "model_pipeline\n",
    "\n",
    "# let's check that the transforms worked\n",
    "model_pipeline[:-1].fit_transform(df_train)\n",
    "\n",
    "model_pipeline.fit(df_train, y_train_t, estimate__sample_weight=w_train_t)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"coefficient\": np.concatenate(\n",
    "            ([model_pipeline[-1].intercept_], model_pipeline[-1].coef_)\n",
    "        )\n",
    "    },\n",
    "    index=[\"intercept\"] + model_pipeline[-1].feature_names_,\n",
    ").T\n",
    "\n",
    "df_test.loc[:,\"pp_t_glm2\"] = model_pipeline.predict(df_test)\n",
    "df_train.loc[:,\"pp_t_glm2\"] = model_pipeline.predict(df_train)\n",
    "\n",
    "print(\n",
    "    \"training loss t_glm2:  {}\".format(\n",
    "        TweedieDist.deviance(y_train_t, df_train[\"pp_t_glm2\"], sample_weight=w_train_t)\n",
    "        / np.sum(w_train_t)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"testing loss t_glm2:  {}\".format(\n",
    "        TweedieDist.deviance(y_test_t, df_test[\"pp_t_glm2\"], sample_weight=w_test_t)\n",
    "        / np.sum(w_test_t)\n",
    "    )\n",
    ")\n",
    "# Create Boolean mask for test rows \n",
    "test = df[\"sample\"] == \"test\"\n",
    "print(\n",
    "    \"Total claim amount on test set, observed = {}, predicted = {}\".format(\n",
    "        df[\"ClaimAmountCut\"].values[test].sum(),\n",
    "        np.sum(df[\"Exposure\"].values[test] * df_test[\"pp_t_glm2\"]),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Let's use a GBM instead as an estimator.\n",
    "# Steps\n",
    "# 1: Define the modelling pipeline. Tip: This can simply be a LGBMRegressor based on X_train_t from before.\n",
    "# 2. Make sure we are choosing the correct objective for our estimator.\n",
    "model_pipeline = Pipeline([(\"estimate\", LGBMRegressor(objective=\"tweedie\"))])\n",
    "model_pipeline.fit(X_train_t, y_train_t, estimate__sample_weight=w_train_t)\n",
    "df_test.loc[:,\"pp_t_lgbm\"] = model_pipeline.predict(X_test_t)\n",
    "df_train.loc[:,\"pp_t_lgbm\"] = model_pipeline.predict(X_train_t)\n",
    "print(\n",
    "    \"training loss t_lgbm:  {}\".format(\n",
    "        TweedieDist.deviance(y_train_t, df_train[\"pp_t_lgbm\"], sample_weight=w_train_t)\n",
    "        / np.sum(w_train_t)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"testing loss t_lgbm:  {}\".format(\n",
    "        TweedieDist.deviance(y_test_t, df_test[\"pp_t_lgbm\"], sample_weight=w_test_t)\n",
    "        / np.sum(w_test_t)\n",
    "    )\n",
    ")\n",
    "#substantial difference between losses, might overfit for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Let's tune the LGBM to reduce overfitting.\n",
    "# Steps:\n",
    "# 1. Define a `GridSearchCV` object with our lgbm pipeline/estimator. Tip: Parameters for a specific step of the pipeline\n",
    "# can be passed by <step_name>__param. \n",
    "\n",
    "# Note: Typically we tune many more parameters and larger grids,\n",
    "# but to save compute time here, we focus on getting the learning rate\n",
    "# and the number of estimators somewhat aligned -> tune learning_rate and n_estimators\n",
    "cv_u_lgbm = GridSearchCV(\n",
    "    model_pipeline,\n",
    "    {\n",
    "        \"estimate__learning_rate\": [0.01, 0.02, 0.03, 0.04, 0.05, 0.1],\n",
    "        \"estimate__n_estimators\": [50, 100, 150, 200],\n",
    "    },\n",
    "    verbose=2,\n",
    ")\n",
    "cv_u_lgbm.fit(X_train_t, y_train_t, estimate__sample_weight=w_train_t)\n",
    "\n",
    "df_test.loc[:,\"pp_t_lgbm\"] = cv_u_lgbm.best_estimator_.predict(X_test_t)\n",
    "df_train.loc[:,\"pp_t_lgbm\"] = cv_u_lgbm.best_estimator_.predict(X_train_t)\n",
    "\n",
    "print(\n",
    "    \"training loss t_lgbm:  {}\".format(\n",
    "        TweedieDist.deviance(y_train_t, df_train[\"pp_t_lgbm\"], sample_weight=w_train_t)\n",
    "        / np.sum(w_train_t)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"testing loss t_lgbm:  {}\".format(\n",
    "        TweedieDist.deviance(y_test_t, df_test[\"pp_t_lgbm\"], sample_weight=w_test_t)\n",
    "        / np.sum(w_test_t)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Total claim amount on test set, observed = {}, predicted = {}\".format(\n",
    "        df[\"ClaimAmountCut\"].values[test].sum(),\n",
    "        np.sum(df[\"Exposure\"].values[test] * df_test[\"pp_t_lgbm\"]),\n",
    "    )\n",
    ")\n",
    "#[CV] END estimate__learning_rate=0.1, estimate__n_estimators=200; total time=   2.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving best unconstrained lgbm model\n",
    "best_unconstrained_lgbm = cv_u_lgbm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the sorting of the pure premium predictions\n",
    "# Source: https://scikit-learn.org/stable/auto_examples/linear_model/plot_tweedie_regression_insurance_claims.html\n",
    "def lorenz_curve(y_true, y_pred, exposure):\n",
    "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
    "    exposure = np.asarray(exposure)\n",
    "\n",
    "    # order samples by increasing predicted risk:\n",
    "    ranking = np.argsort(y_pred)\n",
    "    ranked_exposure = exposure[ranking]\n",
    "    ranked_pure_premium = y_true[ranking]\n",
    "    cumulated_claim_amount = np.cumsum(ranked_pure_premium * ranked_exposure)\n",
    "    cumulated_claim_amount /= cumulated_claim_amount[-1]\n",
    "    cumulated_samples = np.linspace(0, 1, len(cumulated_claim_amount))\n",
    "    return cumulated_samples, cumulated_claim_amount\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "for label, y_pred in [\n",
    "    (\"LGBM\", df_test[\"pp_t_lgbm\"]),\n",
    "    (\"GLM Benchmark\", df_test[\"pp_t_glm1\"]),\n",
    "    (\"GLM Splines\", df_test[\"pp_t_glm2\"]),\n",
    "]:\n",
    "    ordered_samples, cum_claims = lorenz_curve(\n",
    "        df_test[\"PurePremium\"], y_pred, df_test[\"Exposure\"]\n",
    "    )\n",
    "    gini = 1 - 2 * auc(ordered_samples, cum_claims)\n",
    "    label += f\" (Gini index: {gini: .3f})\"\n",
    "    ax.plot(ordered_samples, cum_claims, linestyle=\"-\", label=label)\n",
    "\n",
    "# Oracle model: y_pred == y_test\n",
    "ordered_samples, cum_claims = lorenz_curve(\n",
    "    df_test[\"PurePremium\"], df_test[\"PurePremium\"], df_test[\"Exposure\"]\n",
    ")\n",
    "gini = 1 - 2 * auc(ordered_samples, cum_claims)\n",
    "label = f\"Oracle (Gini index: {gini: .3f})\"\n",
    "ax.plot(ordered_samples, cum_claims, linestyle=\"-.\", color=\"gray\", label=label)\n",
    "\n",
    "# Random baseline\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", color=\"black\", label=\"Random baseline\")\n",
    "ax.set(\n",
    "    title=\"Lorenz Curves\",\n",
    "    xlabel=\"Fraction of policyholders\\n(ordered by model from safest to riskiest)\",\n",
    "    ylabel=\"Fraction of total claim amount\",\n",
    ")\n",
    "ax.legend(loc=\"upper left\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#START OF PROBLEM SET 4\n",
    "#EX1 MONOTONOCITY CONSTRAINTS\n",
    "#EX1.1 Plotting average claims\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "bin_edges = list(range(50, 260, 10))\n",
    "df['BonusMalusBin'] = pd.cut(df['BonusMalus'], bins=bin_edges, include_lowest=True) #need to specify true, otherwise 50 exluded as first interval open\n",
    "aggregated = df.groupby(\"BonusMalusBin\").apply(\n",
    "    lambda x: np.average(x[\"PurePremium\"])\n",
    ").reset_index(name='WeightedAvgClaim')\n",
    "\n",
    "aggregated['BinMidpoint'] = aggregated['BonusMalusBin'].apply(lambda b: (b.left + b.right) / 2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(aggregated['BinMidpoint'], aggregated['WeightedAvgClaim'], marker='o', linestyle='-', linewidth=2)\n",
    "#custom xaxis for interpretability\n",
    "plt.xlim(40, 230)  \n",
    "plt.xticks(range(50, 230, 10))\n",
    "plt.xticks(fontsize=10)\n",
    "\n",
    "#generating titles\n",
    "plt.title('Weighted Average Claim Amount by BonusMalus', fontsize=14, weight='bold')\n",
    "plt.xlabel('BonusMalus (Binned)', fontsize=12)\n",
    "plt.ylabel('Weighted Average Claim', fontsize=12)\n",
    "plt.grid(visible=True, linestyle='--', alpha=0.6)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#What will/could happen if we do not include a monotonicity constraint?\n",
    "#here breaks are observed and claim amount is generally linearly increasing, but there are notable breaks\n",
    "#130-140 is the first peak and as we move to groups with less and less representation the average claim becomes more volatile\n",
    "#last 7 bins dont include much more than 50 people total and last 3 bins include 4 people overall\n",
    "#except for peak at 130/140 results for well represented values as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#providing numbers of people in each bin\n",
    "binned_data = pd.cut(df[\"BonusMalus\"], bins=bin_edges, include_lowest=True)\n",
    "bin_counts = binned_data.value_counts().sort_index()\n",
    "print(bin_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating placeholder array for monotonic constraints \n",
    "num_features = X_train_t.shape[1]\n",
    "monotonic_constraints = [0] * num_features\n",
    "monotonic_constraints[7] = 1 #(9 predictors in total and listed from 0 so bonus malus index 7)\n",
    "\n",
    "numeric_cols = [\"BonusMalus\", \"Density\"]\n",
    "\n",
    "constrained_lgbm = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\n",
    "            \"estimate\",\n",
    "            GeneralizedLinearRegressor(\n",
    "                family=TweedieDist, l1_ratio=1, fit_intercept=True\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "#renamed pipeline\n",
    "constrained_lgbm = Pipeline([(\"estimate\", LGBMRegressor(objective=\"tweedie\", monotone_constraints=monotonic_constraints))])\n",
    "constrained_lgbm.fit(X_train_t, y_train_t, estimate__sample_weight=w_train_t)\n",
    "df_test.loc[:,\"pp_t_lgbm\"] = constrained_lgbm.predict(X_test_t)\n",
    "df_train.loc[:,\"pp_t_lgbm\"] = constrained_lgbm.predict(X_train_t)\n",
    "print(\n",
    "    \"training loss t_lgbm:  {}\".format(\n",
    "        TweedieDist.deviance(y_train_t, df_train[\"pp_t_lgbm\"], sample_weight=w_train_t)\n",
    "        / np.sum(w_train_t)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"testing loss t_lgbm:  {}\".format(\n",
    "        TweedieDist.deviance(y_test_t, df_test[\"pp_t_lgbm\"], sample_weight=w_test_t)\n",
    "        / np.sum(w_test_t)\n",
    "    )\n",
    ")\n",
    "#different results than the regular lgbm, which is encouraging\n",
    "#greater loss for both expected, as we have introduced further constraints on our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning our constrained lgbm given different learning rates, different number of estimators and \n",
    "cv_c_lgbm = GridSearchCV(\n",
    "    constrained_lgbm,\n",
    "    {\n",
    "        \"estimate__learning_rate\": [0.01, 0.02, 0.03, 0.04, 0.05, 0.1],\n",
    "        \"estimate__n_estimators\": [50, 100, 150, 200],\n",
    "    }\n",
    ")\n",
    "cv_c_lgbm.fit(X_train_t, y_train_t, estimate__sample_weight=w_train_t)\n",
    "\n",
    "df_test.loc[:,\"pp_t_lgbm_constrained\"] = cv_c_lgbm.best_estimator_.predict(X_test_t)\n",
    "df_train.loc[:,\"pp_t_lgbm_constrained\"] = cv_c_lgbm.best_estimator_.predict(X_train_t)\n",
    "\n",
    "print(\n",
    "    \"training loss t_lgbm:  {}\".format(\n",
    "        TweedieDist.deviance(y_train_t, df_train[\"pp_t_lgbm_constrained\"], sample_weight=w_train_t)\n",
    "        / np.sum(w_train_t)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"testing loss t_lgbm:  {}\".format(\n",
    "        TweedieDist.deviance(y_test_t, df_test[\"pp_t_lgbm_constrained\"], sample_weight=w_test_t)\n",
    "        / np.sum(w_test_t)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Total claim amount on test set, observed = {}, predicted = {}\".format(\n",
    "        df[\"ClaimAmountCut\"].values[test].sum(),\n",
    "        np.sum(df[\"Exposure\"].values[test] * df_test[\"pp_t_lgbm_constrained\"]),\n",
    "    )\n",
    ")\n",
    "#higher training loss but a lower testing loss, seems like an improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving best constrained lgbm model\n",
    "best_constrained_lgbm = cv_c_lgbm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX2 LEARNING CURVE\n",
    "#EX2.1 Re-fit the best constrained lgbm estimator\n",
    "import lightgbm as lgb\n",
    "\n",
    "best_constrained_lgbm = cv_c_lgbm.best_estimator_\n",
    "lgbm_model = best_constrained_lgbm.named_steps['estimate']\n",
    "eval_set = [(X_train_t, y_train_t), (X_test_t, y_test_t)]\n",
    "\n",
    "lgbm_model.fit(\n",
    "    X_train_t, y_train_t, \n",
    "    sample_weight=w_train_t, \n",
    "    eval_set=eval_set,\n",
    "    eval_metric='l2',\n",
    "    eval_names=['train', 'test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "lgb.plot_metric(lgbm_model, metric='l2')\n",
    "plt.title('Learning Curve - Constrained LGBM Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and tesing loss values are high and the learning curves are almost horizontal, this may suggest underfitting. The constrained model hasn't learned the relationship in the data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX3: Metrics function\n",
    "\n",
    "def compare_models(X_train_t, y_train_t, X_test_t, y_test_t, sample_weight, monotonic_constraints=None):\n",
    "    # Models\n",
    "    constrained_lgbm = Pipeline([\n",
    "        (\"estimate\", lgb.LGBMRegressor(objective=\"tweedie\", monotone_constraints=monotonic_constraints))\n",
    "    ])\n",
    "    unconstrained_lgbm = Pipeline([(\"estimate\", lgb.LGBMRegressor(objective=\"tweedie\"))])\n",
    "\n",
    "    # Train models\n",
    "    constrained_lgbm.fit(X_train_t, y_train_t, estimate__sample_weight=sample_weight)\n",
    "    unconstrained_lgbm.fit(X_train_t, y_train_t, estimate__sample_weight=sample_weight)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred_constrained = constrained_lgbm.predict(X_test_t)\n",
    "    y_pred_unconstrained = unconstrained_lgbm.predict(X_test_t)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    evaluation_constrained = evaluate_predictions(y_test_t, y_pred_constrained, sample_weight=sample_weight)\n",
    "    evaluation_unconstrained = evaluate_predictions(y_test_t, y_pred_unconstrained, sample_weight=sample_weight)\n",
    "\n",
    "    return {\n",
    "        \"Constrained Model Evaluation\": evaluation_constrained,\n",
    "        \"Unconstrained Model Evaluation\": evaluation_unconstrained\n",
    "    }\n",
    "\n",
    "# Results\n",
    "results = compare_models(X_train_t, y_train_t, X_test_t, y_test_t, w_train_t, monotonic_constraints=monotonic_constraints)\n",
    "\n",
    "print(\"Constrained Model Evaluation:\")\n",
    "print(results[\"Constrained Model Evaluation\"])\n",
    "\n",
    "print(\"\\nUnconstrained Model Evaluation:\")\n",
    "print(results[\"Unconstrained Model Evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX4\n",
    "# Creating explainer for unconstrained LGBM\n",
    "best_unconstrained_lgbm_exp = dx.Explainer(best_unconstrained_lgbm, X_train_t, y_train_t, label=\"Unconstrained LGBM\")\n",
    "\n",
    "# Creating explainer for constrained LGBM\n",
    "best_constrained_lgbm_exp = dx.Explainer(best_constrained_lgbm, X_train_t, y_train_t, label=\"Constrained LGBM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unconstrained LGBM\n",
    "pd_lgbm_unconstrained = best_unconstrained_lgbm_exp.model_profile()\n",
    "# constrained LGBM\n",
    "pd_lgbm_constrained = best_constrained_lgbm_exp.model_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for unconstrained LGBM\n",
    "pd_lgbm_unconstrained.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for constrained LGBM\n",
    "pd_lgbm_constrained.plot()\n",
    "#this makes a lot of sense due to monotonicity constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unconstrained LGBM\n",
    "pd_lgbm_unconstrained_cat = best_unconstrained_lgbm_exp.model_profile(variable_type=\"categorical\")\n",
    "# constrained LGBM\n",
    "pd_lgbm_constrained_cat = best_constrained_lgbm_exp.model_profile(variable_type=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for unconstrained LGBM\n",
    "pd_lgbm_unconstrained_cat.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for constrained LGBM\n",
    "\n",
    "pd_lgbm_constrained_cat.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EX 5.1\n",
    "best_constrained_lgbm_exp\n",
    "best_unconstrained_lgbm_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EX 5.2\n",
    "X_test_t_row1 = X_test_t[0:1]\n",
    "\n",
    "pp_best_constrained_lgbm_exp = best_constrained_lgbm_exp.predict_parts(\n",
    "    new_observation=X_test_t_row1,\n",
    "    type=\"shap\",\n",
    "    label=\"Contribution of each feature to the constrained prediction of the 1st observation\"\n",
    "    )\n",
    "\n",
    "pp_best_unconstrained_lgbm_exp = best_unconstrained_lgbm_exp.predict_parts(\n",
    "    new_observation=X_test_t_row1,\n",
    "    type=\"shap\",\n",
    "    label=\"Contribution of each feature to the unconstrained prediction of the 1st observation\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_best_constrained_lgbm_exp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_best_unconstrained_lgbm_exp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contribution of BonusMalus to the predicted value differs across our constrained and unconstrained model which we might expect given the monotonicity constraint imposed in the constrained model which makes the contribution at this relatively low BonusMalus level negative. The direction of the contribution of region and area also varies across the two models perhaps suggesting that their overall relationship to the dependent variable is weak and thus their values adjust readily to compensate for the change in the contribution of BonusMalus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
